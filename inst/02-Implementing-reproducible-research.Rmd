# Implementing reproducible research
  
## Overview

Reproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original researcher [@Goodman341ps12]. This is a cornerstone of the sciences because if we cannot reproduce previous studies, we cannot rely on their results, and we cannot build on them to generate new knowledge. But what does R have to do with such a weighty topic? The answer is that because we interact with R by writing commands in a script file, which we can save, share and archive, we are doing our analysis in a way that can be reproduced. This can be contrasted with analysing data in Excel, SPSS, PAST and other mouse-driven software where many of the intermediate steps are typically mouse-clicks that leave no trace. Another person inspecting your Excel file may struggle to identify the decisions you made in your data anlysis because of the many ephemeral and unrecorded steps that led to the final result.   

Why is reproducibility gaining attention? Four factors have lead to growing concerns about the reproducibility of scientific results in modern science. The first factor is reruns of landmark biomedical experiments that have failed to produce the same results as the initial publication of the experiment [@Prinz2011drugtargets; @Begley2012clinical]. The second factor is the discovery of high-profile studies where the published results were flawed due to simple errors data analysis[@baggerly2009deriving; @Herndon2013austerity]. Third, there has been a sharp rise in the number of scholarly publications that have been retracted due to discoveries of misconduct such as fraudulent data and plagiarism [@Vannoorden2011retractions; @Steen2013retractions]. Finally, there has been a growth of data-intensive research that use massive computer simulations or collect enourmous amounts of data from vast numbers of sensors (ie. astronomy and oceanography). These events have stimulated extensive discussion in many disciplines about how to improve the reproducibility of scientific research. Some of this discussion has resulted in calls from diverse dsicplines [@nosek2015open] for publications to be accompanied by both the raw data that generated the figures in the paper [@reichman2011challenges], and the programming code that shows the steps taken in the data analysis [@barnes2010publish; @Ince1012opencomputer; @Morin2012blackbox]. Related to these calls are a manifesto-like journal articles by groups of researchers that call for substantial changes in the research workflow to improve reproducibilty and transparency [@wilson2014best; @Hampton2015tao; @Sandve2013tenrules]. I have explored these principles in more detail in Marwick [-@Marwick2016JAMT]. 

In this chapter I show how archaeologists can respond to these calls for increased reproducibilty and transparency. I describe two key principles: literate programming  for enabling reproducibilty, and version control for enhancing transparency. Literate programming refers to the use of a computing environment for authoring documents that contain a mix of natural (eg. English) and computer (eg. R) languages [@Schulte2012literate]. Conveniently, R and RStudio are well-equipped to support literate programming, so this practice is relatively easy to learn. The second section of this chapter introduces version control using Git as a principle and tool for enhancing transparency and collaboration. Version control of literate programming files allows you to keep track of all the changes that you and your co-authors make to your files. Using the Git software for version control, you and your collaborators can safely create multiple different versions of your files to experiment with, and either abandon the results, merge them with the main versions, or revert to an earlier version. Athough, neither of these are strictly part of R, R integrates very well with other tools that enable these principles. This makes R unique as an environment for working reproducibly with minimal effort. 

## What does it mean to do reproducible research?

Before showing how we can make our research more reproucible, we should explore exactly what we mean by 'reproducible' because it is not widely used in archaeology. There is variation surrounding the use of the term 'reproducibility' in biology and computer science, especially in comparison to closely related terms such as replicability and reliability [@Baker2016]. Here we follow Stodden's [-@Stodden2014; Stodden2016] defintion and taxnonomy of reproducibility, dividing the concept into three parts: empirical, computational, and statistical.

The first part is empirical reproducibility, also called 'replicability'. For an archaeologist, this means evaluating a previously obtained result by re-excavating a site that another researcher had previously excavated, studying a museum collection that had previously been analysed by another person, or repeating an experiement that has been previously published. Empirical reproducibility is about returning to the source of the data and physically collecting the data again. Archaeologists do this routinely, for example, we return to famous sites such as Star Carr, Catal Huyuk, and Niah Cave to excavate them again. Usually this happens decades after the original excavation that make the site prominent. This is not exact empirical reproducibility, because we do not use the exact procedures of the previous workers, but instead use modern field methods to extract more data from the site, and improve upon and extend the earlier work. But the general idea of testing the previous claims about the site is usually the key motivation for returning to it. 

The second and third parts of 'reproducibility' are computational and statistical reproducibility. Computational reproducibility refers to redoing the calculations of another researcher's quantitative results using their original datasets and methods (i.e. code). This type of reproducibility does not involve independent data collection, but instead uses the methods and data collected by the original investigator. Enhancing computational reproducibility includes preseving the steps of how raw data are cleaned, tidied, and combined or separated in preparation for anlaysis and visualisation. Statistical reproducibility is enhanced when detailed information is provided about the choice of statistical tests, model parameters, threshold values, and other details that determine the outcomes of statistical analyses. 

Computational and statistical reproducibilty are less familiar to most archaeologists, because our disciplinary culture tends to value secrecy and privacy, rather than sharing and openness of the mundane details of our analyses. Many archaeologists view the production of a research publication like the writing of a novel. The creative processes and drafting of the novel is typically a personal, private process that the author keeps to themself. Similarly, the readers of the novel generally have no expectation to see these drafts or have any exposure to the creative process. The author and the reader have a shared understanding that the published novel is the final product, and no other materials from the creative process (e.g. earlier drafts, notes, outlines) are needed to make sense of it. This is because the novel is primarily an aesthetic product, its value coming from how it arouses the emotions of the reader. Early drafts of the novel are typically irrelevant to the aesthetic value of the final published novel. 

Archaeological research, like other sciences, is fundamentally different from novel-writing. The value of archaeological publication is primarily not aesthetic, but in the truth-values of the claims made about human behvaiour in the past. In order to make a robust assessment of these claims, the reader may need to know details of the analytical process that are not presented in the final publication. There are many reasons why relavant details might not be inlcuded in a publcation. In my experience of emails I've recieved from people querying my publications, the main reasons why they ask for further details are that some details were omitted were omitted to stay in the word limits of the journal, or they ask about details that I failed to anticipate would be relevant to the article. The later case is interesting because it shows that we as authors don't have the final say on what data and method details are necessary to make our case. Whatever our readers (e.g. peer reviewers) demand is what counts as the necessary data and methods details. This scholarly author-reader relationship is very different from the novel author-reader relationship. In our case, by making publiclly available our data and our code, we make it a lot easier for our readers to find the materials they need to evaluate our claims and resuse our work. 

Our publications rarely include enough of the data to enable exact reanalysis, and our methods are rarely presented in enough detail to allow another person to independantly repeat our analysis unabimguously. This type of reproducibility is becoming an important issue for recent archaeological research due to advances in technology and the rapid spread of computational methods for many kinds of basic archaeological analysis. This can make it difficult to trust published research, and difficult for others to use newly published research in their own work. In my view, the short answer to improving computational and statistical reproducibility in archaeology is for archaeologists to include data files and programming code with their publications. These extra documents will allow another researcher to see all the steps from when the raw data entered the researcher's computer to the end point where these data were summarised and visualised in a journal article. Literate programming methods are an efficient solution to this problem of combining code with the narratice text of publcations and reports. 
 
## Literate programming

The general principle of literate programming is to write code and text in one document so that a human reader can easily understand the purpose of the code [@knuth1992literate]. Writing like this improves reproducibility because a reader can see the details of the analytical methods used to compute the statisticals, tables and plots of the publication or report. We do not need to copy and paste results from one program to another, because the code produces the results _in situ_. This elimintes the risk of errors from copy-pasting into a word document. This approach also improves efficiency because we have the code and text in one place, simplifying the organisation of our files.

Using R we have several options for doing literate programming. The one I receommend is centred on the `knitr` package and the `markdown` plain text format. It is easy to learn, very well supported with extnsive documentation [@YihuiKnitrBook], and enables all the usual scholarly writing requirements, such as captioning figures and tables, cross-referencing, citations and complex notation. The file format we use for this is called R Markdown, and has the .Rmd suffx. The key components of a typical Rmd file are the metadata (usually a section at the top of the document), the narrative text, and the code chunks.

The metadata section is defined by three dashes at the top and bottom of the section. In this section, we can indicate the title, author, date and many other details of the document. Crucially we can also specify what type of document to render the Rmd into, e.g. Microsoft Word document, PDF or HTML file, as well as document-level details such as whether or not to include a table of contents, what style to use for the citations and reference list, and what template should be used to style the rendered document. Here is an example of the metadata section from the Rmd file of one of my articles: 

```
---
title: 'Landform boundary effects on Holocene forager landscape use in arid South Australia'
author:
- Ben Marwick (corresponding author)
- Peter Hiscock      
- Marjorie Sullivan     
- Philip Hughes       
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   bookdown::word_document2:
    fig_caption: yes
    reference_docx: templates/template.docx
abstract: |
  Landscapes throughout any region vary in the resources they contain. We investigate how Holocene forager populations adapted to this variation in the linear sand dune desert of arid South Australia. We use data from surface scatters of stone artefacts collected during pedestrian survey to compare behaviors at landform boundaries to behaviours at the centers of landforms. We propose a model of human use of the landscape that predicts the prehistoric occupants of the study are were sensitive to the different economic potential of subtly dissimilar landscapes.  In evaluating the model we find that there are different densities of archaeological sites in each landscape type. We also find indications of a boundary effect resulting from people having used marginal areas of each landscape type in response to the resource characteristics of adjoining landforms. In addition, we make some observations on our field data collection methods, identifying the general conditions where mobile GIS may be optimally efficient for archaeological survey
---
```

The langauge of this metadata is not R, but a format called YAML, and is distinctive with its `key: value` patterns. This example shows just a few of the possible metadata fields. The title, author and abstract fields are straightforward, but you can see that the date field has some R code that will insert the current date when the document is rendered. This means that the outputted docx file will automatically have the date of the latest change, and I don't have to worry about updating that. The output field shows that I have used the `word_document2()` function from the `bookdown` package to render this Rmd into a Microsoft Word document. 

I have also indicated that I want to show the figure captions in the output doucment with `fig_caption: yes`. The line `reference_docx: templates/template.docx` indicates that I am using a docx file called  `template.docx` as custom template to add some styling to my output. In this specific case, the `template.docx` adds line numbers to the rendered docx file, specifies Times New Roman as the body text font, and a few other minor adjustments to meet the submission requirements of our target journal. The rticles package by RStudio provdes Rmd templates for manuscripts for several major scholarly publishers. Many Rmd metadata fields are documented at rmarkdown.rstudio.com, and https://www.rstudio.org/links/r_markdown_reference_guide. I have also found many useful examples of Rmd metadata by browsing and searching github.com.    

The RStudio text editor does not include any tools for formatting your text _in situ_, for example you cannot make words appear in the editor with bold or italic characters. This is a deliberate design, and is typical among text editing programs used for writing code. When we use Microsoft Word, we are using a "what you see is what you get" editor -- we edit a document in a form resembling the final printed or presented document. The RStudio text editor is typical of text editors designed for coding in taking a different approach to formatting documents. When working with a plain text editor, we type unformatted plain text and code, and among the text we include instructions on how the final document should appear. We will discuss this further in Chapter XX, but as a quick example, if we wanted a word in bold, we would code it like `**this**`. In this example, the two asterix symbols will be interpreted by our computer when we convert our source document into a final version, such as a PDF, to produce a document with **this** word in bold.     

This method of creating documents is very common in disciplines such as mathematics and physics, where complex equations are written using code because for many people it is easier to write code to produce equations than use a mouse to click on menus and buttons to select the special characters needed for equations. LaTeX is a widely used code-based document preparation system, with particular strengths in complex formatting needed by technical scientific documents. Although highly flexible, LaTeX is also complex and verbose, requiring a lot of typing to add the formatting code to your document. But don't worry, in this book we will use a much simpler document preparation system, known as markdown. We will discuss markdown in more detail in chapter XX, for now the main thing to know is that we use the text editor to write code and text. The advantage of these plain-text document preparation systems such as markdown is that     

## Version control


## Summary

In this chapter I described two principles, literate programming and version control. These are dervied from computer science research and have been adopted by other disciplines, such as ecology and political science, to enable computational and statistical reproducibility. I also demonstrate the current software tools (Rmarkdown, knitr, and Git) that allow us to put these principles into practice. Over time, these software tools will change, and perhaps be replaced by something completely different. However, the principles that they are based on will endure, and are worth becoming familiar with as key concepts in computational and statistical reproducibility. 



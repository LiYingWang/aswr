# Implementing reproducible research
  
## Overview

Reproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original researcher [@Goodman341ps12]. This is a cornerstone of the sciences because if we cannot reproduce previous studies, we cannot rely on their results, and we cannot build on them to generate new knowledge. But what does R have to do with such a weighty topic? The answer is that because we interact with R by writing commands in a script file, which we can save, share and archive, we are doing our analysis in a way that can be reproduced. This can be contrasted with analysing data in Excel, SPSS, PAST and other mouse-driven software where many of the intermediate steps are typically mouse-clicks that leave no trace. Another person inspecting your Excel file may struggle to identify the decisions you made in your data anlysis because of the many ephemeral and unrecorded steps that led to the final result.   

Why is reproducibility gaining attention? Four factors have lead to growing concerns about the reproducibility of scientific results in modern science. The first factor is reruns of landmark biomedical experiments that have failed to produce the same results as the initial publication of the experiment [@Prinz2011drugtargets; @Begley2012clinical]. The second factor is the discovery of high-profile studies where the published results were flawed due to simple errors data analysis[@baggerly2009deriving; @Herndon2013austerity]. Third, there has been a sharp rise in the number of scholarly publications that have been retracted due to discoveries of misconduct such as fraudulent data and plagiarism [@Vannoorden2011retractions; @Steen2013retractions]. Finally, there has been a growth of data-intensive research that use massive computer simulations or collect enourmous amounts of data from vast numbers of sensors (ie. astronomy and oceanography). These events have stimulated extensive discussion in many disciplines about how to improve the reproducibility of scientific research. Some of this discussion has resulted in calls from diverse dsicplines [@nosek2015open] for publications to be accompanied by both the raw data that generated the figures in the paper [@reichman2011challenges], and the programming code that shows the steps taken in the data analysis [@barnes2010publish; @Ince1012opencomputer; @Morin2012blackbox]. Related to these calls are a manifesto-like journal articles by groups of researchers that call for substantial changes in the research workflow to improve reproducibilty and transparency [@wilson2014best; @Hampton2015tao; @Sandve2013tenrules].

In this chapter I show how archaeologists can respond to these calls for increased reproducibilty and transparency. I describe two key principles: literate programming  for enabling reproducibilty, and version control for enhancing transparency. Literate programming refers to the use of a computing environment for authoring documents that contain a mix of natural (eg. English) and computer (eg. R) languages [@Schulte2012literate]. Conveniently, R and RStudio are well-equipped to support literate programming, so this practice is relatively easy to learn. The second section of this chapter introduces version control using Git as a principle and tool for enhancing transparency and collaboration. Version control of literate programming files allows you to keep track of all the changes that you and your co-authors make to your files. Using the Git software for version control, you and your collaborators can safely create multiple different versions of your files to experiment with, and either abandon the results, merge them with the main versions, or revert to an earlier version. Athough, neither of these are strictly part of R, R integrates very well with other tools that enable these principles. This makes R unique as an environment for working reproducibly with minimal effort. 

## What does it mean to do reproducible research?

Before showing how we can make our research more reproucible, we should explore exactly what we mean by 'reproducible' because it is not widely used in archaeology. There is variation surrounding the use of the term 'reproducibility' in biology and computer science, especially in comparison to closely related terms such as replicability and reliability [@Baker2016]. Here we follow Stodden's [-@Stodden2014; Stodden2016] defintion and taxnonomy of reproducibility, dividing the concept into three parts: empirical, computational, and statistical.

The first part is empirical reproducibility, also called 'replicability'. For an archaeologist, this means evaluating a previously obtained result by re-excavating a site that another researcher had previously excavated, studying a museum collection that had previously been analysed by another person, or repeating an experiement that has been previously published. Empirical reproducibility is about returning to the source of the data and physically collecting the data again. Archaeologists do this routinely, for example, we return to famous sites such as Star Carr, Catal Huyuk, and Niah Cave to excavate them again. Usually this happens decades after the original excavation that make the site prominent. This is not exact empirical reproducibility, because we do not use the exact procedures of the previous workers, but instead use modern field methods to extract more data from the site, and improve upon and extend the earlier work. But the general idea of testing the previous claims about the site is usually the key motivation for returning to it. 

The second and third parts of 'reproducibility' are computational and statistical reproducibility. Computational reproducibility refers to redoing the calculations of another researcher's quantitative results using their original datasets and methods (i.e. code). This type of reproducibility does not involve independent data collection, but instead uses the methods and data collected by the original investigator. Statistical reproducibility in enhanced when detailed information is provided about the choice of statistical tests, model parameters, threshold values, and other details that determine the outcomes of statistical analyses. 

Computational and statistical reproducibilty are less familiar to most archaeologists, because our disciplinary culture tends to value secrecy and privacy, rather than sharing and openness of the details of our analyses. Our publications rarely include enough of the data to enable exact reanalysis, and our methods are rarely presented in enough detail to allow another person to independantly repeat our analysis unabimguously. This type of reproducibility is becoming an important issue for recent archaeological research due to advances in technology and the rapid spread of computational methods for many kinds of basic archaeological analysis. This can make it difficult to trust published research, and difficult for others to use newly published research in their own work. In my view, the short answer to improving computational and statistical reproducibility in archaeology is for archaeologists to include data files and programming code with their publications. These extra documents will allow another researcher to see all the steps from when the raw data entered the researcher's computer to the end point where these data were summarised and visualised in a journal article. I have discussed this in more detail, with examples, in Marwick [-@Marwick2016JAMT].
 
## Literate programming

The general principle of literate programming is to write code and text in one document so that a human reader can easily understand the purpose of the code [@knuth1992literate]. Writing like this improves reproducibility because a reader can see the details of the analytical methods used to compute the statisticals, tables and plots of the publication or report. We do not need to copy and paste results from one program to another, because the code produces the results _in situ_. This elimintes the risk of errors from copy-pasting into a word document. This approach also improves efficiency because we have the code and text in one place, simplifying the organisation of our files.

Using R we have several options for doing literate programming. Two of the most popular options depend on contributed packages: Sweave and knitr

The text editor does not include any tools for formatting your text _in situ_, for example you cannot make words appear in the editor with bold or italic characters. This is a deliberate design, and is typical among text editing programs used for writing code. When we use Microsoft Word, we are using a "what you see is what you get" editor -- we edit a document in a form resembling the final printed or presented document. The RStudio text editor is typical of text editors designed for coding in taking a different approach to formatting documents. When working with a plain text editor, we type unformatted plain text and code, and among the text we include instructions on how the final document should appear. We will discuss this further in Chapter XX, but as a quick example, if we wanted a word in bold, we would code it like `**this**`. In this example, the two asterix symbols will be interpreted by our computer when we convert our source document into a final version, such as a PDF, to produce a document with **this** word in bold.     

This method of creating documents is very common in disciplines such as mathematics and physics, where complex equations are written using code because for many people it is easier to write code to produce equations than use a mouse to click on menus and buttons to select the special characters needed for equations. LaTeX is a widely used code-based document preparation system, with particular strengths in complex formatting needed by technical scientific documents. Although highly flexible, LaTeX is also complex and verbose, requiring a lot of typing to add the formatting code to your document. But don't worry, in this book we will use a much simpler document preparation system, known as markdown. We will discuss markdown in more detail in chapter XX, for now the main thing to know is that we use the text editor to write code and text. The advantage of these plain-text document preparation systems such as markdown is that     

## Version control


## Summary

In this chapter I described two principles, literate programming and version control. These are dervied from computer science research and have been adopted by other disciplines, such as ecology and political science, to enable computational and statistical reproducibility. I also demonstrate the current software tools (Rmarkdown, knitr, and Git) that allow us to put these principles into practice. Over time, these software tools will change, and perhaps be replaced by something completely different. However, the principles that they are based on will endure, and are worth becoming familiar with as key concepts in computational and statistical reproducibility. 



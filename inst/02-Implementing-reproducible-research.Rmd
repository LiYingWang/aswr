# Implementing reproducible research
  
## Overview

Reproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original researcher [@Goodman341ps12]. This is a cornerstone of the sciences because if we cannot reproduce previous studies, we cannot rely on their results, and we cannot build on them to generate new knowledge. But what does R have to do with such a weighty topic? The answer is that because we interact with R by writing commands in a script file, which we can save, share and archive, we are doing our analysis in a way that can be reproduced. This can be contrasted with analysing data in Excel, SPSS, PAST and other mouse-driven software where many of the intermediate steps are typically mouse-clicks that leave no trace. Another person inspecting your Excel file may struggle to identify the decisions you made in your data anlysis because of the many ephemeral and unrecorded steps that led to the final result.   

Why is reproducibility gaining attention? Four factors have lead to growing concerns about the reproducibility of scientific results in modern science. The first factor is reruns of landmark biomedical experiments that have failed to produce the same results as the initial publication of the experiment [@Prinz2011drugtargets; @Begley2012clinical]. The second factor is the discovery of high-profile studies where the published results were flawed due to simple errors data analysis[@baggerly2009deriving; @Herndon2013austerity]. Third, there has been a sharp rise in the number of scholarly publications that have been retracted due to discoveries of misconduct such as fraudulent data and plagiarism [@Vannoorden2011retractions; @Steen2013retractions]. Finally, there has been a growth of data-intensive research that use massive computer simulations or collect enourmous amounts of data from vast numbers of sensors (ie. astronomy and oceanography). These events have stimulated extensive discussion in many disciplines about how to improve the reproducibility of scientific research. Some of this discussion has resulted in calls from diverse dsicplines [@nosek2015open] for publications to be accompanied by both the raw data that generated the figures in the paper [@reichman2011challenges], and the programming code that shows the steps taken in the data analysis [@barnes2010publish; @Ince1012opencomputer; @Morin2012blackbox]. Related to these calls are a manifesto-like journal articles by groups of researchers that call for substantial changes in the research workflow to improve reproducibilty and transparency [@wilson2014best; @Hampton2015tao; @Sandve2013tenrules]. I have explored these principles in more detail in Marwick [-@Marwick2016JAMT]. 

In this chapter I show how archaeologists can respond to these calls for increased reproducibilty and transparency. I describe two key principles: literate programming  for enabling reproducibilty, and version control for enhancing transparency. Literate programming refers to the use of a computing environment for authoring documents that contain a mix of natural (eg. English) and computer (eg. R) languages [@Schulte2012literate]. Conveniently, R and RStudio are well-equipped to support literate programming, so this practice is relatively easy to learn. The second section of this chapter introduces version control using Git as a principle and tool for enhancing transparency and collaboration. Version control of literate programming files allows you to keep track of all the changes that you and your co-authors make to your files. Using the Git software for version control, you and your collaborators can safely create multiple different versions of your files to experiment with, and either abandon the results, merge them with the main versions, or revert to an earlier version. Athough, neither of these are strictly part of R, R integrates very well with other tools that enable these principles. This makes R unique as an environment for working reproducibly with minimal effort. 

## What does it mean to do reproducible research?

Before showing how we can make our research more reproucible, we should explore exactly what we mean by 'reproducible' because it is not widely used in archaeology. There is variation surrounding the use of the term 'reproducibility' in biology and computer science, especially in comparison to closely related terms such as replicability and reliability [@Baker2016]. Here we follow Stodden's [-@Stodden2014; Stodden2016] defintion and taxnonomy of reproducibility, dividing the concept into three parts: empirical, computational, and statistical.

The first part is empirical reproducibility, also called 'replicability'. For an archaeologist, this means evaluating a previously obtained result by re-excavating a site that another researcher had previously excavated, studying a museum collection that had previously been analysed by another person, or repeating an experiement that has been previously published. Empirical reproducibility is about returning to the source of the data and physically collecting the data again. Archaeologists do this routinely, for example, we return to famous sites such as Star Carr, Catal Huyuk, and Niah Cave to excavate them again. Usually this happens decades after the original excavation that make the site prominent. This is not exact empirical reproducibility, because we do not use the exact procedures of the previous workers, but instead use modern field methods to extract more data from the site, and improve upon and extend the earlier work. But the general idea of testing the previous claims about the site is usually the key motivation for returning to it. 

The second and third parts of 'reproducibility' are computational and statistical reproducibility. Computational reproducibility refers to redoing the calculations of another researcher's quantitative results using their original datasets and methods (i.e. code). This type of reproducibility does not involve independent data collection, but instead uses the methods and data collected by the original investigator. Enhancing computational reproducibility includes preseving the steps of how raw data are cleaned, tidied, and combined or separated in preparation for anlaysis and visualisation. Statistical reproducibility is enhanced when detailed information is provided about the choice of statistical tests, model parameters, threshold values, and other details that determine the outcomes of statistical analyses. 

Computational and statistical reproducibilty are less familiar to most archaeologists, because our disciplinary culture tends to value secrecy and privacy, rather than sharing and openness of the mundane details of our analyses. Many archaeologists view the production of a research publication like the writing of a novel. The creative processes and drafting of the novel is typically a personal, private process that the author keeps to themself. Similarly, the readers of the novel generally have no expectation to see these drafts or have any exposure to the creative process. The author and the reader have a shared understanding that the published novel is the final product, and no other materials from the creative process (e.g. earlier drafts, notes, outlines) are needed to make sense of it. This is because the novel is primarily an aesthetic product, its value coming from how it arouses the emotions of the reader. Early drafts of the novel are typically irrelevant to the aesthetic value of the final published novel. Of course there are exceptions, for example we often enjoy to hear the author of a novel speak about their inspirations and motives in interviews, and literary scholars find value in the notes and paraphenalia of writers. For the most part, however, these details are not part of the unspoken contract between the fiction writer and their readers 

Archaeological research, like other sciences, is fundamentally different from novel-writing, although traditional scholarly norms of not sharing anything except the final published article tend to reinforce the novel-writing model. The value of an archaeological publication is primarily not aesthetic, but in the truth-values of the claims made about human behvaiour in the past. In order to make a robust assessment of these claims, the reader may need to know details of the analytical process that are not presented in the final publication. There are many reasons why relavant details might not be inlcuded in a publcation. Primarily, we cannot anticipate and address every potential question in the limited space of a typical journal article. These kinds of private correspondences between readers and authors are common, and imply an interesting defintion of what data are in a research context. The implication is that that we as authors don't have the final say on what data and method details are necessary to make our case. Whatever our readers (e.g. peer reviewers, other scholars) demand is what counts as the necessary data and methods details. This scholarly author-reader relationship is very different from the novel author-reader relationship. In our case, by making publiclly available our data and our code at the point of publication of our articles, we make it a lot easier for our readers to find the materials they need to evaluate our claims and resuse our work. Many fields are shifting their scholarly practices in recognition of this special relationship between author and reader. A full account is beyond the scope of this chapter, but betailed desriptions of these new ways of doing science are available for Oceanography [@lowndes2017our] and soil science [@bond2016running].

Retunging to the question of computational reprodubility, I believe one of the most pressing problems is that our research publications rarely include enough of the data to enable exact reanalysis, and our methods are rarely presented in enough detail to allow another person to independantly repeat our analysis unabimguously. This type of reproducibility is becoming an important issue for recent archaeological research due to advances in technology and the rapid spread of computational methods for many kinds of basic archaeological analysis. This can make it difficult to trust published research, and difficult for others to use newly published research in their own work. In my view, the short answer to improving computational and statistical reproducibility in archaeology is for archaeologists to include data files and programming code with their publications. These extra documents will allow another researcher to see all the steps from when the raw data entered the researcher's computer to the end point where these data were summarised and visualised in a journal article. Literate programming methods are an efficient solution to this problem of combining code with the narratice text of publcations and reports. 
 
## Literate programming

The general principle of literate programming is to write code and text in one document so that a human reader can easily understand the purpose of the code [@knuth1992literate]. Writing like this improves reproducibility because a reader can see the details of the analytical methods used to compute the statisticals, tables and plots of the publication or report. We do not need to copy and paste results from one program to another, because the code produces the results _in situ_. This elimintes the risk of errors from copy-pasting into a word document. This approach also improves efficiency because we have the code and text in one place, simplifying the organisation of our files.

Using R we have several options for doing literate programming. The one I receommend is centred on the `knitr` package and the `markdown` plain text format. It is easy to learn, very well supported with extnsive documentation [@YihuiKnitrBook], and enables all the usual scholarly writing requirements, such as captioning figures and tables, cross-referencing, citations and complex notation. The file format we use for this is called R Markdown, and has the .Rmd suffx. The key components of a typical Rmd file are the metadata (usually a section at the top of the document), the narrative text, and the code blocks

### Document metadata

The metadata section is defined by three dashes at the top and bottom of the section. In this section, we can indicate the title, author, date and many other details of the document. Crucially we can also specify what type of document to render the Rmd into, e.g. Microsoft Word document, PDF or HTML file, as well as document-level details such as whether or not to include a table of contents, what style to use for the citations and reference list, and what template should be used to style the rendered document. Here is an example of the metadata section from the Rmd file of one of my articles: 

```
---
title: 'Movement of lithics by trampling: An experiment in the Madjedbebe sediments, northern Australia'
author:
- Ben Marwick
- Elspeth Hayes
- Chris Clarkson
- Richard Fullagar
date: '`r Sys.Date()`'
output:
   bookdown::word_document2:
    fig_caption: yes
    reference_docx: templates/template.docx
bibliography: trampling.bib
csl: journal-of-archaeological-science.csl
abstract: |
  Understanding post-depositional movement of artefacts is vital to making reliable claims about the formation of archaeological deposits. Human trampling has long been recognised as a contributor to post-depositional artefact displacement. We investigate the degree to which artefact form (shape-and-size) attributes can predict how an artefact is moved by trampling. We use the Zingg classification system to describe artefact form. Our trampling substrate is the recently excavated archaeological deposits from Madjedbebe, northern Australia. Madjedbebe is an important site because it contains early evidence of human activity in Australia. The age of artefacts at Madjedbebe is contentious because of the possibility of artefacts moving due to trampling. We trampled artefacts in Madjedbebe sediments and measured their displacement, as well as modelling the movement of artefacts by computer simulation. Artefact elongation is a significant predictor of horizontal distance moved by trampling, and length, width, thickness and volume are significant predictors of the vertical distance. The explanatory power of these artefact variables is small, indicating that many other factors are also important in determining how an artefact moves during trampling. Our experiment indicates that trampling has not contributed to extensive downward displacement of artefacts at Madjedbebe.
keywords: |
  Trampling; Artifact movement; Experimental archaeology; Australia; Simulation
---
```

The langauge of this metadata is not R, but a format called YAML, and is distinctive with its `key: value` patterns. This example shows just a few of the possible metadata fields. The title, author and abstract fields are straightforward, but you can see that the date field has some R code that will insert the current date when the document is rendered. This means that the outputted docx file will automatically have the date of the latest change, and I don't have to worry about updating that. The output field shows that I have used the `word_document2()` function from the `bookdown` package to render this Rmd into a Microsoft Word document. I have also indicated that I want to show the figure captions in the output doucment with `fig_caption: yes`. The line `reference_docx: templates/template.docx` indicates that I am using a docx file called  `template.docx` as custom template to add some styling to my output. In this specific case, the `template.docx` adds line numbers to the rendered docx file, specifies Times New Roman as the body text font, and a few other minor adjustments to meet the submission requirements of our target journal. The rticles package by RStudio provdes Rmd templates for manuscripts for several major scholarly publishers. Many Rmd metadata fields are documented at rmarkdown.rstudio.com, and https://www.rstudio.org/links/r_markdown_reference_guide. I have also found many useful examples of Rmd metadata by browsing and searching github.com. 

We can also see the file containing the bibliographical information specified at `bibliography:`, and a file that gives the in-text citation and reference list style at `csl:` (citation style language). R Markdown can handle bibliography files in a variety of formats, including RIS, EndNote's .enl and BibTeX's .bib. I typically use BibTex, and my `.bib` file is one I create by copying and pasting the reference details from various sources, such as my reference manager library (e.g. EndNote, Mendeley, Zotero) or directly from Google Scholar. The `.csl` is one I copied directly from a collection of journal citation styles (e.g. from <http://citationstyles.org/>). Here are the bibliographic details for one of the items in the `.bib` file for this book:

```
@article{Marwick2016JAMT,
year={2016},
issn={1072-5369},
journal={Journal of Archaeological Method and Theory},
doi={10.1007/s10816-015-9272-9},
title={Computational Reproducibility in Archaeological Research: Basic Principles and a Case Study of Their Implementation},
url={http://dx.doi.org/10.1007/s10816-015-9272-9},
publisher={Springer US},
keywords={Reproducible research; Computer programming; Software engineering; Australian archaeology; Open science},
author={Marwick, Ben},
pages={1-27},
language={English}
}
```

Most of the lines in the above example are easy to understand attributes of a bibliographic reference. Perhaps the most important detail is in the first line, `Marwick2016JAMT`, which is the key that we used to link the in-text citation to these bibliographic details. To include a citation of this paper in my R markdown file, I type `[@Marwick2016JAMT]`, and this is rendered in the output document as a nicely formatted citation like this: [@Marwick2016JAMT]. All of the usual variations of in-text citations are possible with this notation:

Effect  | Markdown notation | Result
------------- | ----------------------- |  ----------------------- |
Complex combinations of citations | `...some narrative text... [see @Marwick2016JAMT, pp. 13-15; also @knuth1992literate, ch. 1].` | ...some narrative text... [see @Marwick2016JAMT, pp. 13-15; also @knuth1992literate, ch. 1].
Page ranges | `...some narrative text... [@Marwick2016JAMT, pp. 13-15, 18-19 and elsewhere].` | ...some narrative text... [@Marwick2016JAMT, pp. 13-15, 18-19 and elsewhere].
Multiple citations | `...some narrative text...  [@Marwick2016JAMT; @knuth1992literate].` | ...some narrative text...  [@Marwick2016JAMT; @knuth1992literate].
Date-only citation | `Marwick says you should use a scripting language for your analysis [-@Marwick2016JAMT].` | Marwick says you should use a scripting language for your analysis [-@Marwick2016JAMT]
Use author's name in text | `@Marwick2016JAMT says you should use a scripting language for your analysis.` | @Marwick2016JAMT says you should use a scripting language for your analysis.
Use author's name and page number | `@Marwick2016JAMT [p. 13] ays you should use a scripting language for your analysis.`| @Marwick2016JAMT [p. 13] says you should use a scripting language for your analysis 


...more about citations...

### Narrative text

The RStudio text editor does not include any tools for formatting your text _in situ_, for example you cannot make words appear in the editor with bold or italic characters. This is a deliberate design, and is typical among text editing programs used for writing code. When we use Microsoft Word, we are using a "what you see is what you get" editor -- we edit a document in a form resembling the final printed or presented document. The RStudio text editor is typical of text editors designed for coding in taking a different approach to formatting documents. When working with a plain text editor, we type unformatted plain text and code, and among the text we include instructions on how the final document should appear. We will discuss this further in Chapter XX, but as a quick example, if we wanted a word in italics, we would code it like `*this*`. In this example, the two asterix symbols will be interpreted by our computer when we convert our source document into a final version, such as a PDF, to produce a document with *this* word in italics. Headings and subheadings are indicated by `#` symbols, the top level heading has a single `#` directly preceeding the header text, and second and third level headings have `##` and `###`, and so on, like so: 

```
# Header 1

## Header 2

### Header 3
```

This method of creating documents is very common in disciplines such as mathematics and physics, where complex equations are written using code because for many people it is easier to write code to produce equations than use a mouse to click on menus and buttons to select the special characters needed for equations. LaTeX is a widely used code-based document preparation system, with particular strengths in complex formatting needed by technical scientific documents. Although highly flexible, LaTeX is also complex and verbose, requiring a lot of typing to add the formatting code to your document.  The advantage of Markdown as a plain-text document preparation systems is that the document is uncluttered with formatting code for typical writing, but LaTeX can be used where more complex symbols, expressions or formatting are necessary. The following table shows how to generate commonly used symbols in a R Markdown document, the notation surrounded by dollar signs `$` is LaTeX notation:

Symbol  | Markdown/LaTeX notation 
------------- | -------------
per mille  ‰  | `$\text{\textperthousand}$`
delta δ  | `$\delta$` 
plus-minus ± | `$\pm$` 
degree ° | `$\text{\textdegree}$`
subscript CO~2~ | `CO~2~`
superscript E=mc^2^ | `E=mc^2^`




### Code blocks and inline code

...code chunks...

...captions and cros references...

   

    

## Version control


## Summary

In this chapter I described two principles, literate programming and version control. These are dervied from computer science research and have been adopted by other disciplines, such as ecology and political science, to enable computational and statistical reproducibility. I also demonstrate the current software tools (Rmarkdown, knitr, and Git) that allow us to put these principles into practice. Over time, these software tools will change, and perhaps be replaced by something completely different. However, the principles that they are based on will endure, and are worth becoming familiar with as key concepts in computational and statistical reproducibility. 


